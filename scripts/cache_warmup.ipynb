{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "project_directory = '..'\n",
    "sys.path.append(os.path.abspath(project_directory))\n",
    "\n",
    "import tinycudann as tcnn\n",
    "import commentjson as ctjs\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import NamedTuple\n",
    "from plyfile import PlyData, PlyElement\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postfixs=['F_4']\n",
    "ntc_conf_paths=['../configs/cache/cache_'+postfix+'.json' for postfix in postfixs]\n",
    "pcd_path='../test/flame_steak_suite/flame_steak_init/point_cloud/iteration_15000/point_cloud.ply'\n",
    "save_paths=['../ntc/flame_steak_ntc_params_'+postfix+'.pth' for postfix in postfixs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicPointCloud(NamedTuple):\n",
    "    points : np.array\n",
    "    colors : np.array\n",
    "    normals : np.array\n",
    "\n",
    "def fetchXYZ(path):\n",
    "    plydata = PlyData.read(path)\n",
    "    xyz = np.stack((np.asarray(plydata.elements[0][\"x\"]),\n",
    "                    np.asarray(plydata.elements[0][\"y\"]),\n",
    "                    np.asarray(plydata.elements[0][\"z\"])),  axis=1)\n",
    "    return torch.tensor(xyz, dtype=torch.float, device=\"cuda\")\n",
    "\n",
    "def get_xyz_bound(xyz, percentile=80):\n",
    "    ## Hard-code the coordinate of the corners here!!\n",
    "    return torch.tensor([-20, -15,   5]).cuda(), torch.tensor([15, 10, 23]).cuda()\n",
    "\n",
    "def get_contracted_xyz(xyz):\n",
    "    xyz_bound_min, xyz_bound_max = get_xyz_bound(xyz, 80)\n",
    "    normalzied_xyz=(xyz-xyz_bound_min)/(xyz_bound_max-xyz_bound_min)\n",
    "    return normalzied_xyz\n",
    "\n",
    "@torch.compile\n",
    "def quaternion_multiply(a, b):\n",
    "    a_norm=nn.functional.normalize(a)\n",
    "    b_norm=nn.functional.normalize(b)\n",
    "    w1, x1, y1, z1 = a_norm[:, 0], a_norm[:, 1], a_norm[:, 2], a_norm[:, 3]\n",
    "    w2, x2, y2, z2 = b_norm[:, 0], b_norm[:, 1], b_norm[:, 2], b_norm[:, 3]\n",
    "\n",
    "    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2\n",
    "    x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2\n",
    "    y = w1 * y2 + y1 * w2 + z1 * x2 - x1 * z2\n",
    "    z = w1 * z2 + z1 * w2 + x1 * y2 - y1 * x2\n",
    "\n",
    "    return torch.stack([w, x, y, z], dim=1)\n",
    "\n",
    "def quaternion_loss(q1, q2):\n",
    "    cos_theta = F.cosine_similarity(q1, q2, dim=1)\n",
    "    cos_theta = torch.clamp(cos_theta, -1+1e-7, 1-1e-7)\n",
    "    return 1-torch.pow(cos_theta, 2).mean()\n",
    "\n",
    "def l1loss(network_output, gt):\n",
    "    return torch.abs((network_output - gt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntcs=[]\n",
    "for ntc_conf_path in ntc_conf_paths:    \n",
    "    with open(ntc_conf_path) as ntc_conf_file:\n",
    "        ntc_conf = ctjs.load(ntc_conf_file)\n",
    "    ntc=tcnn.NetworkWithInputEncoding(n_input_dims=3, n_output_dims=8, encoding_config=ntc_conf[\"encoding\"], network_config=ntc_conf[\"network\"]).to(torch.device(\"cuda\"))\n",
    "    ntc_optimizer = torch.optim.Adam(ntc.parameters(), lr=1e-4)\n",
    "    xyz=fetchXYZ(pcd_path)\n",
    "    normalzied_xyz=get_contracted_xyz(xyz)\n",
    "    mask = (normalzied_xyz >= 0) & (normalzied_xyz <= 1)\n",
    "    mask = mask.all(dim=1)\n",
    "    ntc_inputs=torch.cat([normalzied_xyz[mask]],dim=-1)\n",
    "    noisy_inputs = ntc_inputs + 0.01 * torch.rand_like(ntc_inputs)\n",
    "    d_xyz_gt=torch.tensor([0.,0.,0.]).cuda()\n",
    "    d_rot_gt=torch.tensor([1.,0.,0.,0.]).cuda()\n",
    "    dummy_gt=torch.tensor([1.]).cuda()\n",
    "    def cacheloss(resi):\n",
    "        masked_d_xyz=resi[:,:3]\n",
    "        masked_d_rot=resi[:,3:7]\n",
    "        masked_dummy=resi[:,7:8]\n",
    "        loss_xyz=l1loss(masked_d_xyz,d_xyz_gt)\n",
    "        loss_rot=quaternion_loss(masked_d_rot,d_rot_gt)\n",
    "        loss_dummy=l1loss(masked_dummy,dummy_gt)\n",
    "        loss=loss_xyz+loss_rot+loss_dummy\n",
    "        return loss\n",
    "    for iteration in range(0,3000):      \n",
    "        ntc_inputs_w_noisy = torch.cat([noisy_inputs, ntc_inputs, torch.rand_like(ntc_inputs)],dim=0)  \n",
    "        ntc_output=ntc(ntc_inputs_w_noisy)\n",
    "        loss=cacheloss(ntc_output)\n",
    "        if iteration % 100 ==0:\n",
    "            print(loss)\n",
    "        loss.backward()\n",
    "        ntc_optimizer.step()\n",
    "        ntc_optimizer.zero_grad(set_to_none = True)\n",
    "    ntcs.append(ntc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ntc import NeuralTransformationCache\n",
    "for idx, save_path in enumerate(save_paths):\n",
    "    ntc=NeuralTransformationCache(ntcs[idx],get_xyz_bound(xyz)[0],get_xyz_bound(xyz)[1])\n",
    "    torch.save(ntc.state_dict(),save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.0py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
